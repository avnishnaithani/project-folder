{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd9da33c-493a-4c23-b767-70e9421e0c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.2.0-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in ./anaconda3/lib/python3.12/site-packages (from xgboost) (1.26.4)\n",
      "Collecting nvidia-nccl-cu12 (from xgboost)\n",
      "  Downloading nvidia_nccl_cu12-2.29.3-py3-none-manylinux_2_18_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: scipy in ./anaconda3/lib/python3.12/site-packages (from xgboost) (1.16.3)\n",
      "Downloading xgboost-3.2.0-py3-none-manylinux_2_28_x86_64.whl (131.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.7/131.7 MB\u001b[0m \u001b[31m175.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.29.3-py3-none-manylinux_2_18_x86_64.whl (289.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.8/289.8 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\n",
      "Successfully installed nvidia-nccl-cu12-2.29.3 xgboost-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28e3fd6b-ff61-48eb-b3a0-3b23320b73e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target column: income\n",
      "Saved 6 model pipeline files to: model\n",
      "Saved metrics table to: model/metrics_comparison.csv\n",
      "\n",
      "=== Metrics Comparison (sorted by AUC) ===\n",
      "              Model  Accuracy      AUC  Precision   Recall       F1      MCC\n",
      "            XGBoost  0.868724 0.922962   0.772762 0.644133 0.702609 0.623495\n",
      "Logistic_Regression  0.853063 0.902445   0.739233 0.602041 0.663620 0.575799\n",
      "      Random_Forest  0.848303 0.892875   0.726917 0.592474 0.652846 0.561847\n",
      "                KNN  0.837402 0.866877   0.684822 0.601403 0.640407 0.537816\n",
      "      Decision_Tree  0.815292 0.752058   0.613284 0.630102 0.621579 0.499519\n",
      "        Naive_Bayes  0.536619 0.733448   0.335973 0.947066 0.495992 0.323665\n"
     ]
    }
   ],
   "source": [
    "# train_models_universal.py\n",
    "\n",
    "#\n",
    "# What it does (assignment-aligned):\n",
    "# 1) Loads Adult Income CSV\n",
    "# 2) Cleans '?' -> NaN, trims strings\n",
    "# 3) Trains 6 models on SAME dataset (with preprocessing inside pipeline)\n",
    "# 4) Computes required metrics and saves metrics_comparison.csv\n",
    "# 5) Saves 6 trained pipelines into ./model (or /content/model in Colab)\n",
    "# 6) If running in Colab: zips and downloads the model folder automatically\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    matthews_corrcoef,\n",
    ")\n",
    "\n",
    "import joblib\n",
    "\n",
    "# XGBoost (required model)\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Environment detection\n",
    "# -----------------------------\n",
    "def running_in_colab() -> bool:\n",
    "    try:\n",
    "        import google.colab  \n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def normalize_strings(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Strip spaces and convert '?' to NaN for object columns.\"\"\"\n",
    "    out = df.copy()\n",
    "    for col in out.columns:\n",
    "        if out[col].dtype == \"object\":\n",
    "            out[col] = out[col].astype(str).str.strip()\n",
    "            out[col] = out[col].replace(\"?\", np.nan)\n",
    "    return out\n",
    "\n",
    "\n",
    "def detect_target_column(df: pd.DataFrame) -> str:\n",
    "    \"\"\"Adult Income usually uses 'income'. Fall back to last column.\"\"\"\n",
    "    for c in [\"income\", \"Income\", \"salary\", \"Salary\", \"class\", \"Class\", \"target\", \"Target\"]:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return df.columns[-1]\n",
    "\n",
    "\n",
    "def binarize_target(y: pd.Series) -> pd.Series:\n",
    "    \"\"\"Map <=50K / >50K (and dotted variants) to 0/1.\"\"\"\n",
    "    y_str = y.astype(str).str.strip().str.replace(\".\", \"\", regex=False)\n",
    "    mapping = {\"<=50K\": 0, \">50K\": 1, \"0\": 0, \"1\": 1, \"False\": 0, \"True\": 1}\n",
    "    y_bin = y_str.map(mapping)\n",
    "    if y_bin.isna().any():\n",
    "        # fallback if labels are different but binary\n",
    "        uniques = sorted(y_str.dropna().unique().tolist())\n",
    "        if len(uniques) == 2:\n",
    "            auto_map = {uniques[0]: 0, uniques[1]: 1}\n",
    "            y_bin = y_str.map(auto_map)\n",
    "        else:\n",
    "            raise ValueError(f\"Unrecognized target labels: {sorted(set(y_str.unique().tolist()))}\")\n",
    "    return y_bin.astype(int)\n",
    "\n",
    "\n",
    "def make_preprocessor(X: pd.DataFrame) -> ColumnTransformer:\n",
    "    \"\"\"Dense OneHot so GaussianNB doesn't fail on sparse matrices.\"\"\"\n",
    "    num_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]\n",
    "    cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "\n",
    "    numeric_pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Version-safe dense one-hot (sklearn >=1.2 uses sparse_output)\n",
    "    try:\n",
    "        ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    except TypeError:\n",
    "        ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "    categorical_pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"onehot\", ohe),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_pipe, num_cols),\n",
    "            (\"cat\", categorical_pipe, cat_cols),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "    )\n",
    "\n",
    "\n",
    "def auc_safe(y_true: np.ndarray, y_proba: np.ndarray) -> float:\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return float(\"nan\")\n",
    "    return float(roc_auc_score(y_true, y_proba))\n",
    "\n",
    "\n",
    "def compute_metrics(y_true: np.ndarray, y_pred: np.ndarray, y_proba: np.ndarray) -> dict:\n",
    "    return {\n",
    "        \"Accuracy\": float(accuracy_score(y_true, y_pred)),\n",
    "        \"AUC\": auc_safe(y_true, y_proba),\n",
    "        \"Precision\": float(precision_score(y_true, y_pred, zero_division=0)),\n",
    "        \"Recall\": float(recall_score(y_true, y_pred, zero_division=0)),\n",
    "        \"F1\": float(f1_score(y_true, y_pred, zero_division=0)),\n",
    "        \"MCC\": float(matthews_corrcoef(y_true, y_pred)),\n",
    "    }\n",
    "\n",
    "\n",
    "# ------------------\n",
    "# Training + saving \n",
    "# ------------------\n",
    "def train_and_save(\n",
    "    csv_path: str,\n",
    "    out_dir: str,\n",
    "    test_size: float = 0.2,\n",
    "    random_state: int = 42,\n",
    "):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = normalize_strings(df)\n",
    "\n",
    "    target_col = detect_target_column(df)\n",
    "    y = binarize_target(df[target_col])\n",
    "    X = df.drop(columns=[target_col])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=random_state\n",
    "    )\n",
    "\n",
    "    preprocessor = make_preprocessor(X_train)\n",
    "\n",
    "    models = {\n",
    "        \"Logistic_Regression\": LogisticRegression(max_iter=2000),\n",
    "        \"Decision_Tree\": DecisionTreeClassifier(random_state=random_state),\n",
    "        \"KNN\": KNeighborsClassifier(n_neighbors=7),\n",
    "        \"Naive_Bayes\": GaussianNB(),\n",
    "        \"Random_Forest\": RandomForestClassifier(n_estimators=30, random_state=random_state, n_jobs=-1),\n",
    "        \"XGBoost\": XGBClassifier(\n",
    "            n_estimators=300,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=5,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.9,\n",
    "            reg_lambda=1.0,\n",
    "            random_state=random_state,\n",
    "            eval_metric=\"logloss\",\n",
    "            n_jobs=-1,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    rows = []\n",
    "    for name, model in models.items():\n",
    "        pipe = Pipeline(steps=[(\"prep\", preprocessor), (\"model\", model)])\n",
    "        pipe.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = pipe.predict(X_test)\n",
    "\n",
    "        if hasattr(pipe.named_steps[\"model\"], \"predict_proba\"):\n",
    "            y_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "        elif hasattr(pipe.named_steps[\"model\"], \"decision_function\"):\n",
    "            scores = pipe.decision_function(X_test)\n",
    "            scores = (scores - scores.min()) / (scores.max() - scores.min() + 1e-9)\n",
    "            y_proba = scores\n",
    "        else:\n",
    "            y_proba = y_pred.astype(float)\n",
    "\n",
    "        m = compute_metrics(y_test.values, y_pred, y_proba)\n",
    "        m[\"Model\"] = name\n",
    "        rows.append(m)\n",
    "\n",
    "        joblib.dump(pipe, os.path.join(out_dir, f\"{name}.joblib\"))\n",
    "\n",
    "    metrics_df = pd.DataFrame(rows)[[\"Model\", \"Accuracy\", \"AUC\", \"Precision\", \"Recall\", \"F1\", \"MCC\"]]\n",
    "    metrics_df = metrics_df.sort_values(by=\"AUC\", ascending=False)\n",
    "    metrics_path = os.path.join(out_dir, \"metrics_comparison.csv\")\n",
    "    metrics_df.to_csv(metrics_path, index=False)\n",
    "\n",
    "    print(\"Target column:\", target_col)\n",
    "    print(\"Saved 6 model pipeline files to:\", out_dir)\n",
    "    print(\"Saved metrics table to:\", metrics_path)\n",
    "    print(\"\\n=== Metrics Comparison (sorted by AUC) ===\")\n",
    "    print(metrics_df.to_string(index=False))\n",
    "\n",
    "    return out_dir\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Colab convenience: zip & download (only runs in Colab)\n",
    "# -----------------------------\n",
    "def zip_and_download_if_colab(folder_path: str, zip_name: str):\n",
    "    if not running_in_colab():\n",
    "        return\n",
    "\n",
    "    import shutil\n",
    "    from google.colab import files\n",
    "\n",
    "    if os.path.exists(zip_name):\n",
    "        os.remove(zip_name)\n",
    "\n",
    "    shutil.make_archive(zip_name.replace(\".zip\", \"\"), \"zip\", folder_path)\n",
    "    print(\"Zipped:\", zip_name)\n",
    "    files.download(zip_name)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Universal entry point\n",
    "# -----------------------------\n",
    "def main(csv_path: str = None):\n",
    "    # Default paths depending on environment\n",
    "    if running_in_colab():\n",
    "        default_csv = \"/content/adult.csv\"\n",
    "        default_out = \"/content/model\"\n",
    "        default_zip = \"/content/model.zip\"\n",
    "    else:\n",
    "        default_csv = \"adult.csv\"\n",
    "        default_out = \"model\"\n",
    "        default_zip = \"model.zip\"  \n",
    "\n",
    "    csv_path = csv_path or default_csv\n",
    "\n",
    "    if not os.path.exists(csv_path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"Could not find dataset at: {csv_path}\\n\"\n",
    "            f\"- In Colab, upload adult.csv to /content/\\n\"\n",
    "            f\"- Locally, keep adult.csv in the same folder as this script/notebook\\n\"\n",
    "        )\n",
    "\n",
    "    out_dir = train_and_save(csv_path=csv_path, out_dir=default_out)\n",
    "\n",
    "    # Only Colab will download automatically\n",
    "    zip_and_download_if_colab(folder_path=out_dir, zip_name=default_zip)\n",
    "\n",
    "\n",
    "# In Jupyter: run `main(\"path/to/adult.csv\")` or just `main()`\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
